"""
Interface CLI principale pour FinAgent.
"""

import asyncio
from typing import Optional

import click
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

from ..ai import (
    get_ai_factory, get_service_status, get_available_models,
    create_ai_provider, ModelType, ProviderType
)
from ..ai.config import get_ai_config

console = Console()


@click.group()
@click.option("--config", "-c", help="Chemin vers le fichier de configuration")
@click.option("--verbose", "-v", is_flag=True, help="Mode verbose")
@click.option("--debug", is_flag=True, help="Mode debug")
@click.pass_context
def cli(ctx, config, verbose, debug):
    """ü§ñ FinAgent - Agent IA pour analyse financi√®re"""
    ctx.ensure_object(dict)
    ctx.obj["config"] = config
    ctx.obj["verbose"] = verbose
    ctx.obj["debug"] = debug


@cli.group()
def ai():
    """Commandes pour la gestion des services IA"""
    pass


@ai.command()
async def status():
    """Affiche le statut des services IA"""
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("V√©rification du statut...", total=None)
        
        try:
            status_info = await get_service_status()
            
            # Table des services
            services_table = Table(title="Statut des Services IA")
            services_table.add_column("Service", style="cyan")
            services_table.add_column("Statut", style="bold")
            
            for service, status in status_info.items():
                if service == "providers":
                    continue
                status_style = "green" if status else "red"
                status_text = "‚úÖ Actif" if status else "‚ùå Inactif"
                services_table.add_row(service, f"[{status_style}]{status_text}[/{status_style}]")
            
            console.print(services_table)
            
            # Table des providers
            if "providers" in status_info:
                providers_table = Table(title="Statut des Providers IA")
                providers_table.add_column("Provider", style="cyan")
                providers_table.add_column("Disponible", style="bold")
                providers_table.add_column("Temps de r√©ponse", style="yellow")
                providers_table.add_column("Mod√®les", style="blue")
                providers_table.add_column("Erreur", style="red")
                
                for provider, info in status_info["providers"].items():
                    available = info.get("available", False)
                    status_style = "green" if available else "red"
                    status_text = "‚úÖ" if available else "‚ùå"
                    
                    response_time = info.get("response_time_ms")
                    response_text = f"{response_time:.1f}ms" if response_time else "N/A"
                    
                    models_count = info.get("models_available", 0)
                    models_text = str(models_count) if models_count > 0 else "0"
                    
                    error_text = info.get("error", "")[:50] if info.get("error") else ""
                    
                    providers_table.add_row(
                        provider,
                        f"[{status_style}]{status_text}[/{status_style}]",
                        response_text,
                        models_text,
                        error_text
                    )
                
                console.print(providers_table)
            
        except Exception as e:
            console.print(f"[red]Erreur lors de la v√©rification du statut: {e}[/red]")


@ai.command()
async def models():
    """Liste les mod√®les IA disponibles"""
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("R√©cup√©ration des mod√®les...", total=None)
        
        try:
            available_models = await get_available_models()
            
            for provider, models_list in available_models.items():
                table = Table(title=f"Mod√®les {provider.upper()}")
                table.add_column("Mod√®le", style="cyan")
                table.add_column("Statut", style="green")
                
                if models_list:
                    for model in models_list:
                        table.add_row(model, "‚úÖ Disponible")
                else:
                    table.add_row("Aucun mod√®le", "‚ùå Non disponible")
                
                console.print(table)
            
        except Exception as e:
            console.print(f"[red]Erreur lors de la r√©cup√©ration des mod√®les: {e}[/red]")


@ai.command()
@click.option("--provider", type=click.Choice(["claude", "ollama"]), help="Provider √† tester")
@click.option("--model", help="Mod√®le sp√©cifique √† tester")
async def test(provider, model):
    """Teste la connectivit√© avec les providers IA"""
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("Test de connectivit√©...", total=None)
        
        try:
            # D√©termine le provider
            provider_type = None
            if provider == "claude":
                provider_type = ProviderType.CLAUDE
            elif provider == "ollama":
                provider_type = ProviderType.OLLAMA
            
            # Cr√©e le provider
            ai_provider = await create_ai_provider(provider_type)
            
            if not ai_provider:
                console.print("[red]‚ùå Impossible de cr√©er le provider[/red]")
                return
            
            # D√©termine le mod√®le
            if model:
                try:
                    model_type = ModelType(model)
                except ValueError:
                    console.print(f"[red]‚ùå Mod√®le invalide: {model}[/red]")
                    return
            else:
                # Utilise le mod√®le par d√©faut du provider
                config = get_ai_config()
                if provider_type == ProviderType.CLAUDE:
                    model_type = config.claude.default_model
                elif provider_type == ProviderType.OLLAMA:
                    model_type = config.ollama.default_model
                else:
                    model_type = ModelType.CLAUDE_3_5_SONNET
            
            # Test avec un prompt simple
            test_prompt = "R√©ponds simplement 'OK' si tu re√ßois ce message."
            
            progress.update(task, description="Envoi du test...")
            response = await ai_provider.generate_response(
                test_prompt,
                model=model_type,
                max_tokens=10
            )
            
            if response:
                console.print(f"[green]‚úÖ Test r√©ussi avec {provider_type.value}[/green]")
                console.print(f"[dim]Mod√®le: {model_type.value}[/dim]")
                console.print(f"[dim]R√©ponse: {response[:100]}...[/dim]")
            else:
                console.print(f"[red]‚ùå Test √©chou√©: aucune r√©ponse[/red]")
            
        except Exception as e:
            console.print(f"[red]‚ùå Erreur durant le test: {e}[/red]")


@ai.command()
@click.option("--model", help="Mod√®le Ollama √† t√©l√©charger")
async def pull(model):
    """T√©l√©charge un mod√®le Ollama"""
    if not model:
        console.print("[red]‚ùå Veuillez sp√©cifier un mod√®le √† t√©l√©charger[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task(f"T√©l√©chargement de {model}...", total=None)
        
        try:
            # Valide le mod√®le
            try:
                model_type = ModelType(model)
            except ValueError:
                console.print(f"[red]‚ùå Mod√®le invalide: {model}[/red]")
                return
            
            # R√©cup√®re le service de discovery
            from ..ai.services import get_discovery_service
            discovery_service = await get_discovery_service()
            
            if not discovery_service:
                console.print("[red]‚ùå Service de discovery non disponible[/red]")
                return
            
            # T√©l√©charge le mod√®le
            success = await discovery_service.pull_model(model_type)
            
            if success:
                console.print(f"[green]‚úÖ Mod√®le {model} t√©l√©charg√© avec succ√®s[/green]")
            else:
                console.print(f"[red]‚ùå √âchec du t√©l√©chargement de {model}[/red]")
            
        except Exception as e:
            console.print(f"[red]‚ùå Erreur durant le t√©l√©chargement: {e}[/red]")


@cli.group()
def config():
    """Commandes de configuration"""
    pass


@config.command()
def show():
    """Affiche la configuration actuelle"""
    try:
        ai_config = get_ai_config()
        
        # Panneau de configuration Claude
        claude_info = f"""
[cyan]API Key:[/cyan] {'‚úÖ Configur√©e' if ai_config.claude.api_key else '‚ùå Manquante'}
[cyan]URL de base:[/cyan] {ai_config.claude.base_url}
[cyan]Mod√®le par d√©faut:[/cyan] {ai_config.claude.default_model.value}
[cyan]Timeout:[/cyan] {ai_config.claude.timeout}s
        """
        console.print(Panel(claude_info.strip(), title="Configuration Claude"))
        
        # Panneau de configuration Ollama
        ollama_info = f"""
[cyan]Host:[/cyan] {ai_config.ollama.host}
[cyan]Port:[/cyan] {ai_config.ollama.port}
[cyan]URL compl√®te:[/cyan] {ai_config.ollama.base_url}
[cyan]Mod√®le par d√©faut:[/cyan] {ai_config.ollama.default_model.value}
[cyan]Auto-pull:[/cyan] {'‚úÖ Activ√©' if ai_config.ollama.auto_pull else '‚ùå D√©sactiv√©'}
        """
        console.print(Panel(ollama_info.strip(), title="Configuration Ollama"))
        
        # Panneau de configuration g√©n√©rale
        general_info = f"""
[cyan]Strat√©gie de fallback:[/cyan] {ai_config.fallback_strategy.value}
[cyan]Provider pr√©f√©r√©:[/cyan] {ai_config.preferred_provider.value if ai_config.preferred_provider else 'Auto'}
[cyan]Auto-discovery:[/cyan] {'‚úÖ Activ√©' if ai_config.enable_auto_discovery else '‚ùå D√©sactiv√©'}
[cyan]Intervalle de refresh:[/cyan] {ai_config.discovery_refresh_interval}s
        """
        console.print(Panel(general_info.strip(), title="Configuration G√©n√©rale"))
        
    except Exception as e:
        console.print(f"[red]‚ùå Erreur lors de l'affichage de la configuration: {e}[/red]")


@config.command()
@click.option("--provider", type=click.Choice(["claude", "ollama"]), required=True)
async def setup(provider):
    """Configuration interactive d'un provider"""
    
    if provider == "claude":
        console.print("[cyan]Configuration de Claude[/cyan]")
        
        api_key = click.prompt("Cl√© API OpenRouter", hide_input=True)
        base_url = click.prompt("URL de base", default="https://openrouter.ai/api/v1")
        
        # Sauvegarde temporaire - dans un vrai projet, on sauvegarderait dans un fichier
        console.print("[green]‚úÖ Configuration Claude sauvegard√©e[/green]")
        console.print("[yellow]üí° Red√©marrez l'application pour appliquer les changements[/yellow]")
        
    elif provider == "ollama":
        console.print("[cyan]Configuration d'Ollama[/cyan]")
        
        host = click.prompt("Host Ollama", default="localhost")
        port = click.prompt("Port Ollama", default=11434, type=int)
        
        # Test de connexion
        from ..ai.providers.ollama_provider import create_ollama_provider
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Test de connexion...", total=None)
            
            try:
                provider_instance = create_ollama_provider(host=host, port=port)
                connected = await provider_instance.validate_connection()
                
                if connected:
                    console.print("[green]‚úÖ Connexion Ollama r√©ussie[/green]")
                    console.print("[green]‚úÖ Configuration Ollama sauvegard√©e[/green]")
                else:
                    console.print("[red]‚ùå Impossible de se connecter √† Ollama[/red]")
                    console.print("[yellow]üí° V√©rifiez qu'Ollama est d√©marr√© et accessible[/yellow]")
                
            except Exception as e:
                console.print(f"[red]‚ùå Erreur de connexion: {e}[/red]")


@cli.command()
@click.argument("symbol")
@click.option("--provider", type=click.Choice(["claude", "ollama"]), help="Provider IA √† utiliser")
@click.option("--model", help="Mod√®le sp√©cifique √† utiliser")
async def analyze(symbol, provider, model):
    """Analyse financi√®re d'un symbole boursier"""
    
    console.print(f"[cyan]Analyse de {symbol.upper()}[/cyan]")
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("Initialisation de l'analyse...", total=None)
        
        try:
            # D√©termine le provider
            provider_type = None
            if provider == "claude":
                provider_type = ProviderType.CLAUDE
            elif provider == "ollama":
                provider_type = ProviderType.OLLAMA
            
            # Cr√©e le provider IA
            ai_provider = await create_ai_provider(provider_type, task_type="analysis")
            
            if not ai_provider:
                console.print("[red]‚ùå Impossible de cr√©er le provider IA[/red]")
                return
            
            progress.update(task, description="Analyse en cours...")
            
            # Prompt d'analyse simple
            prompt = f"""
            Analyse le symbole boursier {symbol.upper()}.
            
            Fournis une analyse concise incluant:
            1. Vue d'ensemble de l'entreprise
            2. Position sur le march√©
            3. Tendances r√©centes
            4. Recommandation g√©n√©rale
            
            R√©ponds en fran√ßais et de mani√®re structur√©e.
            """
            
            # D√©termine le mod√®le
            if model:
                try:
                    model_type = ModelType(model)
                except ValueError:
                    console.print(f"[yellow]‚ö†Ô∏è Mod√®le invalide, utilisation du mod√®le par d√©faut[/yellow]")
                    model_type = None
            else:
                model_type = None
            
            response = await ai_provider.generate_response(
                prompt,
                model=model_type,
                max_tokens=1000
            )
            
            if response:
                console.print(Panel(response, title=f"Analyse de {symbol.upper()}"))
            else:
                console.print("[red]‚ùå Aucune r√©ponse de l'IA[/red]")
            
        except Exception as e:
            console.print(f"[red]‚ùå Erreur durant l'analyse: {e}[/red]")


# Point d'entr√©e async pour les commandes
def run_async_command(coro):
    """Wrapper pour ex√©cuter des commandes async avec click"""
    def wrapper(*args, **kwargs):
        return asyncio.run(coro(*args, **kwargs))
    return wrapper


# Application des wrappers async
ai.command()(run_async_command(status))
ai.command()(run_async_command(models))
ai.command()(run_async_command(test))
ai.command()(run_async_command(pull))
config.command()(run_async_command(setup))
cli.command()(run_async_command(analyze))


if __name__ == "__main__":
    cli()
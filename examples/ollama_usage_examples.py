#!/usr/bin/env python3
"""
Exemples d'usage de l'int√©gration Ollama dans FinAgent

Ce fichier contient des exemples pratiques d'utilisation des diff√©rents
mod√®les Ollama pour diverses t√¢ches financi√®res.
"""

import asyncio
import logging
from typing import Dict, List
from datetime import datetime

from finagent.ai import create_ai_provider, get_ai_factory
from finagent.ai.models.base import ModelType, ProviderType
from finagent.ai.config import AIConfig, OllamaConfig, FallbackStrategy


# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OllamaExamples:
    """Classe contenant les exemples d'usage d'Ollama."""
    
    def __init__(self):
        self.factory = None
    
    async def initialize(self):
        """Initialise la factory AI."""
        self.factory = await get_ai_factory()
        logger.info("Factory AI initialis√©e")
    
    async def example_basic_usage(self):
        """Exemple d'usage basique avec Ollama."""
        print("\n" + "="*60)
        print("EXEMPLE 1: Usage basique d'Ollama")
        print("="*60)
        
        try:
            # Cr√©ation d'un provider Ollama
            provider = await create_ai_provider(ProviderType.OLLAMA)
            
            # Test de connectivit√©
            is_connected = await provider.validate_connection()
            if not is_connected:
                print("‚ùå Ollama n'est pas disponible")
                return
            
            print("‚úÖ Connexion Ollama √©tablie")
            
            # G√©n√©ration d'une r√©ponse simple
            prompt = "Qu'est-ce que la diversification d'un portefeuille ?"
            
            print(f"\nüìù Prompt: {prompt}")
            print("\nü§ñ R√©ponse Ollama:")
            
            response = await provider.generate_response(
                prompt,
                model=ModelType.LLAMA3_1_8B,
                max_tokens=500,
                temperature=0.7
            )
            
            print(response)
            
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
    
    async def example_model_comparison(self):
        """Compare diff√©rents mod√®les Ollama sur la m√™me t√¢che."""
        print("\n" + "="*60)
        print("EXEMPLE 2: Comparaison de mod√®les")
        print("="*60)
        
        # Mod√®les √† tester
        models_to_test = [
            ModelType.LLAMA3_1_8B,
            ModelType.MISTRAL_7B,
            ModelType.GEMMA_7B,
            ModelType.PHI3_MINI
        ]
        
        prompt = """
        Analyse les risques d'un investissement en crypto-monnaies.
        Fournis 3 points cl√©s en moins de 100 mots.
        """
        
        provider = await create_ai_provider(ProviderType.OLLAMA)
        
        for model in models_to_test:
            print(f"\nüîç Test avec {model.value}:")
            print("-" * 40)
            
            try:
                start_time = datetime.now()
                
                response = await provider.generate_response(
                    prompt,
                    model=model,
                    max_tokens=200,
                    temperature=0.5
                )
                
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                print(f"‚è±Ô∏è  Dur√©e: {duration:.2f}s")
                print(f"üìÑ R√©ponse: {response[:200]}...")
                
            except Exception as e:
                print(f"‚ùå Erreur avec {model.value}: {e}")
    
    async def example_financial_analysis(self):
        """Exemple d'analyse financi√®re compl√®te."""
        print("\n" + "="*60)
        print("EXEMPLE 3: Analyse financi√®re avec Ollama")
        print("="*60)
        
        # Configuration pour analyse financi√®re
        provider = await create_ai_provider(task_type="analysis")
        
        analysis_prompt = """
        Analyse l'action Tesla (TSLA) selon ces crit√®res :

        1. **Performance r√©cente** : √âvolution du cours sur 6 mois
        2. **Position concurrentielle** : Avantages vs autres constructeurs EV
        3. **Risques** : Principaux d√©fis et menaces
        4. **Opportunit√©s** : Catalyseurs de croissance potentiels
        5. **Recommandation** : Achat, conservation ou vente avec justification

        Fournis une analyse structur√©e et objective en fran√ßais.
        """
        
        print("üìä Analyse de Tesla (TSLA) en cours...")
        
        try:
            response = await provider.generate_response(
                analysis_prompt,
                max_tokens=1200,
                temperature=0.3  # Plus d√©terministe pour l'analyse
            )
            
            print("\n" + "="*50)
            print("ANALYSE TESLA (TSLA)")
            print("="*50)
            print(response)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'analyse: {e}")
    
    async def example_portfolio_optimization(self):
        """Exemple d'optimisation de portefeuille."""
        print("\n" + "="*60)
        print("EXEMPLE 4: Optimisation de portefeuille")
        print("="*60)
        
        provider = await create_ai_provider(ProviderType.OLLAMA)
        
        portfolio_prompt = """
        J'ai un portefeuille de 50,000‚Ç¨ avec cette r√©partition actuelle :
        - Actions tech US: 40% (AAPL, MSFT, GOOGL)
        - Actions europ√©ennes: 20% (ASML, SAP)
        - Obligations: 25%
        - Cash: 15%

        Mon profil : 35 ans, horizon 15 ans, tol√©rance au risque mod√©r√©e.

        Propose une r√©partition optimis√©e avec justifications :
        1. Allocation d'actifs recommand√©e
        2. Secteurs √† renforcer ou r√©duire
        3. Strat√©gie de r√©√©quilibrage
        4. Instruments √† consid√©rer (ETF, etc.)
        """
        
        print("üéØ Optimisation de portefeuille en cours...")
        
        try:
            response = await provider.generate_response(
                portfolio_prompt,
                model=ModelType.LLAMA3_1_8B,
                max_tokens=1500,
                temperature=0.4
            )
            
            print("\n" + "="*50)
            print("RECOMMANDATIONS D'OPTIMISATION")
            print("="*50)
            print(response)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'optimisation: {e}")
    
    async def example_coding_assistant(self):
        """Exemple d'assistance au d√©veloppement avec CodeLlama."""
        print("\n" + "="*60)
        print("EXEMPLE 5: Assistant de d√©veloppement")
        print("="*60)
        
        provider = await create_ai_provider(ProviderType.OLLAMA)
        
        coding_prompt = """
        √âcris une fonction Python qui calcule les indicateurs techniques suivants
        pour une s√©rie de prix :
        
        1. Moyenne mobile simple (SMA) sur N p√©riodes
        2. RSI (Relative Strength Index)
        3. Bandes de Bollinger
        
        La fonction doit :
        - Accepter une liste de prix et les param√®tres
        - Retourner un dictionnaire avec les indicateurs
        - Inclure la gestion d'erreurs
        - √ätre bien document√©e
        """
        
        print("üíª G√©n√©ration de code avec CodeLlama...")
        
        try:
            response = await provider.generate_response(
                coding_prompt,
                model=ModelType.CODELLAMA_7B,
                max_tokens=1500,
                temperature=0.2  # Tr√®s d√©terministe pour le code
            )
            
            print("\n" + "="*50)
            print("CODE G√âN√âR√â")
            print("="*50)
            print(response)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration de code: {e}")
    
    async def example_fallback_strategy(self):
        """Exemple de strat√©gie de fallback Claude <-> Ollama."""
        print("\n" + "="*60)
        print("EXEMPLE 6: Strat√©gie de fallback")
        print("="*60)
        
        # Test avec diff√©rentes strat√©gies
        strategies = [
            FallbackStrategy.OLLAMA_TO_CLAUDE,
            FallbackStrategy.CLAUDE_TO_OLLAMA,
            FallbackStrategy.AUTO
        ]
        
        prompt = "Explique l'effet de l'inflation sur les investissements."
        
        for strategy in strategies:
            print(f"\nüîÑ Test strat√©gie: {strategy.value}")
            print("-" * 40)
            
            try:
                # Configuration personnalis√©e
                config = AIConfig(
                    fallback_strategy=strategy,
                    enable_auto_discovery=True
                )
                
                # Provider avec configuration personnalis√©e
                provider = await create_ai_provider(
                    task_type="analysis",
                    config=config
                )
                
                response = await provider.generate_response(
                    prompt,
                    max_tokens=300
                )
                
                # Affichage du provider utilis√©
                provider_info = getattr(provider, '_provider_type', 'unknown')
                print(f"‚úÖ Provider utilis√©: {provider_info}")
                print(f"üìù R√©ponse (extrait): {response[:150]}...")
                
            except Exception as e:
                print(f"‚ùå Erreur avec strat√©gie {strategy.value}: {e}")
    
    async def example_model_discovery(self):
        """Exemple d'utilisation du service de discovery."""
        print("\n" + "="*60)
        print("EXEMPLE 7: Discovery des mod√®les")
        print("="*60)
        
        try:
            from finagent.ai.services import get_discovery_service
            
            discovery = await get_discovery_service()
            
            # Rafra√Æchissement des mod√®les
            print("üîç D√©couverte des mod√®les disponibles...")
            models_info = await discovery.refresh_models()
            
            if models_info:
                print(f"‚úÖ {len(models_info)} mod√®les d√©tect√©s:")
                for model_type, info in models_info.items():
                    status = "‚úÖ Disponible" if info.available else "‚ùå Non disponible"
                    print(f"  - {model_type.value}: {status}")
                    if info.size_mb:
                        print(f"    Taille: {info.size_mb} MB")
            else:
                print("‚ùå Aucun mod√®le d√©tect√©")
            
            # Recommandations par t√¢che
            print("\nüí° Recommandations par t√¢che:")
            tasks = ["analysis", "coding", "conversation", "summarization"]
            
            for task in tasks:
                recommended = discovery.get_recommended_models_for_task(task)
                print(f"  - {task}: {[m.value for m in recommended[:3]]}")
            
            # Test de t√©l√©chargement (simulation)
            print("\nüì• Test de t√©l√©chargement de mod√®le...")
            model_to_pull = ModelType.GEMMA_7B
            
            if model_to_pull in [m for m in discovery.get_available_models()]:
                print(f"‚úÖ {model_to_pull.value} d√©j√† disponible")
            else:
                print(f"üì• T√©l√©chargement de {model_to_pull.value}...")
                # success = await discovery.pull_model(model_to_pull)
                # Note: Comment√© pour √©viter de t√©l√©charger automatiquement
                print("üí≠ (T√©l√©chargement simul√© - d√©commentez pour ex√©cuter)")
        
        except Exception as e:
            print(f"‚ùå Erreur lors de la discovery: {e}")
    
    async def example_health_monitoring(self):
        """Exemple de monitoring de sant√© des providers."""
        print("\n" + "="*60)
        print("EXEMPLE 8: Monitoring de sant√©")
        print("="*60)
        
        try:
            # Statut de sant√© des providers
            health_status = self.factory.get_provider_health_status()
            
            print("üè• √âtat de sant√© des providers:")
            print("-" * 40)
            
            for provider_name, status in health_status.items():
                if status.get("available", False):
                    response_time = status.get("response_time_ms", 0)
                    print(f"‚úÖ {provider_name}: Disponible ({response_time:.1f}ms)")
                    
                    # Informations sp√©cifiques √† Ollama
                    if provider_name == "ollama":
                        models_count = status.get("models_available", 0)
                        print(f"   üìö Mod√®les disponibles: {models_count}")
                else:
                    print(f"‚ùå {provider_name}: Non disponible")
            
            # Test de connectivit√© d√©taill√©
            print("\nüîß Tests de connectivit√© d√©taill√©s:")
            
            # Test Ollama
            try:
                ollama_provider = await create_ai_provider(ProviderType.OLLAMA)
                is_connected = await ollama_provider.validate_connection()
                print(f"  Ollama: {'‚úÖ OK' if is_connected else '‚ùå √âchec'}")
            except Exception as e:
                print(f"  Ollama: ‚ùå Erreur - {e}")
            
            # Test Claude
            try:
                claude_provider = await create_ai_provider(ProviderType.CLAUDE)
                # Note: Le test de Claude n√©cessite une API key valide
                print("  Claude: üí≠ (N√©cessite API key)")
            except Exception as e:
                print(f"  Claude: ‚ùå Erreur - {e}")
        
        except Exception as e:
            print(f"‚ùå Erreur lors du monitoring: {e}")
    
    async def run_all_examples(self):
        """Ex√©cute tous les exemples."""
        print("üöÄ D√©marrage des exemples d'usage Ollama")
        print("=" * 60)
        
        await self.initialize()
        
        examples = [
            self.example_basic_usage,
            self.example_model_comparison,
            self.example_financial_analysis,
            self.example_portfolio_optimization,
            self.example_coding_assistant,
            self.example_fallback_strategy,
            self.example_model_discovery,
            self.example_health_monitoring
        ]
        
        for i, example in enumerate(examples, 1):
            try:
                print(f"\nüîÑ Ex√©cution exemple {i}/{len(examples)}...")
                await example()
                print(f"‚úÖ Exemple {i} termin√©")
            except Exception as e:
                print(f"‚ùå Erreur exemple {i}: {e}")
                continue
        
        print("\n" + "="*60)
        print("‚úÖ Tous les exemples ont √©t√© ex√©cut√©s")
